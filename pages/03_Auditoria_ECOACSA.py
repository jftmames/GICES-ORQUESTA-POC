import streamlit as st
import json

# Importamos el cerebro y utilidades compartidas
try:
    import modules.gices_brain as gices_brain
    import modules.shared_helpers as sh
except ImportError:
    st.error("‚ùå Error CR√çTICO: M√≥dulos no disponibles. Revise gices_brain.py y shared_helpers.py.")
    gices_brain = None
    sh = None

# --- DATOS DE SIMULACI√ìN REALISTA (E4 - Biodiversidad) ---
SIMULATED_DATA = {
    "project_id": "MRN-2024-003",
    "esrs_data_point": "E4-5 (Area de Ecosistema Restaurada)",
    "ecosystem_type": "Bosque de Kelp (Marina)",
    "permanence_guarantee_years": 15,
}
RAG_QUERY = "¬øCu√°les son los requisitos de permanencia y adicionalidad para cr√©ditos de naturaleza marina seg√∫n la Hoja de Ruta 2025 y el Reglamento de Restauraci√≥n?"


# --- APP PRINCIPAL (03_Auditoria_ECOACSA.py) ---
def main():
    st.set_page_config(
        page_title="GICES ORQUESTA - 03. AUDITOR√çA ECOACSA",
        page_icon="üõ°Ô∏è",
        layout="wide"
    )

    st.title("üõ°Ô∏è GICES ORQUESTA - 03. TEST DE COINCIDENCIA ECOACSA")
    st.caption("Paso 3 del Pipeline: Auditor√≠a E4 (Biodiversidad) y Validaci√≥n de Integridad (M√°quina vs. Humano).")

    if not gices_brain or not sh:
        return

    # --- 1. INPUTS DE DATOS Y VEREDICTO HUMANO ---
    st.subheader("1. Dato de Campo y Veredicto Humano (Entrada)")
    
    col_human, col_data_input = st.columns([1, 2])
    
    with col_human:
        human_verdict = st.selectbox(
            "Veredicto Humano Esperado:",
            options=['RIESGO', 'CUMPLE', 'NO CUMPLE', 'RIESGO MEDIO'],
            index=0, 
            key="human_verdict_input"
        )
        human_gap = st.text_area(
            "Brecha Principal Identificada por Humano:",
            value="La garant√≠a de permanencia de 15 a√±os incumple el criterio de Alta Integridad de la Hoja de Ruta UE.",
            key="human_gap_input"
        )

    with col_data_input:
        real_data_input = st.text_area(
            "Pegar Dato Crudo E4 Real (JSON):",
            value=json.dumps(SIMULATED_DATA, indent=2),
            height=250,
            key="real_data_input"
        )
    
    st.divider()

    # --- 2. L√ìGICA DE EJECUCI√ìN (CON TRANSPARENCIA) ---
    if st.button("üõ°Ô∏è Ejecutar Test de Coincidencia", type="primary", use_container_width=True):
        
        with st.status("üîç **Fase 2: Ejecutando RAG y Deliberaci√≥n Cognitiva...**", expanded=True) as status:
            try:
                # A. Determinar datos a auditar
                try:
                    test_data = json.loads(real_data_input)
                except json.JSONDecodeError:
                    status.write("Advertencia: JSON inv√°lido. Usando simulaci√≥n de respaldo.")
                    test_data = SIMULATED_DATA

                # B. RAG Sem√°ntico (Recuperaci√≥n de Contexto)
                status.write("Paso B: **B√∫squeda Vectorial (RAG)** de la normativa relevante.")
                with st.expander("üîé **Query RAG Enviado al Cerebro Vectorial**", expanded=False):
                    st.code(RAG_QUERY, language="text")
                    
                context_chunks = gices_brain.retrieve_context(RAG_QUERY, k=4)
                
                # Protocolo de Transparencia: Evidencia recuperada
                with st.expander("üìÑ **Evidencia Normativa Recuperada**", expanded=False):
                    if context_chunks:
                        for c in context_chunks:
                            st.markdown(f"**Fuente:** {c['source']} (P√°g. {c['page']}) | Score: {c.get('score', 0):.2f}")
                            st.caption(f"...{c['content'][:400]}...")
                            st.divider()
                    else:
                        st.error("‚ùå No se encontr√≥ evidencia relevante. La base vectorial puede estar vac√≠a.")

                # C. An√°lisis Deliberativo (GPT-4o)
                status.write("Paso C: **Deliberaci√≥n** - Cruzando el Dato vs. Normativa.")
                
                # Para transparencia, necesitamos el prompt. Simularemos el retorno del prompt
                if hasattr(gices_brain.deliberative_analysis, '__code__') and 'return_prompt' in gices_brain.deliberative_analysis.__code__.co_varnames:
                    temp_result = gices_brain.deliberative_analysis(test_data, context_chunks, mode="ECOACSA Biodiversity Integrity", return_prompt=True)
                    prompt_to_gpt = temp_result["prompt"]
                    machine_result = gices_brain.deliberative_analysis(test_data, context_chunks, mode="ECOACSA Biodiversity Integrity")
                else:
                    prompt_to_gpt = "Prompt no disponible por configuraci√≥n de gices_brain.py."
                    machine_result = gices_brain.deliberative_analysis(test_data, context_chunks, mode="ECOACSA Biodiversity Integrity")

                # Protocolo de Transparencia: Prompt enviado
                with st.expander("ü§ñ **Prompt Enviado al Auditor GPT-4o**", expanded=False):
                    st.code(prompt_to_gpt, language="markdown")
                
                machine_check = machine_result.get("compliance_check", "UNKNOWN").upper().replace("RIESGO ALTO", "RIESGO").replace("RIESGO MEDIO", "RIESGO")
                status.update(label="‚úÖ **An√°lisis de Deliberaci√≥n Completo**", state="complete")

            except Exception as e:
                status.update(label="‚ùå **Error Cr√≠tico en el Proceso**", state="error")
                st.error(f"Error: {e}")
                return

        # --- 3. RESULTADOS Y COMPARACI√ìN ---
        st.subheader("2. Resultados del An√°lisis")
        col_ai, col_human_output = st.columns(2)
        
        # Columna de la IA
        with col_ai:
            st.markdown("#### Veredicto de la M√°quina (GICES-RAGA)")
            if "RIESGO" in machine_check: st.error(f"‚ö†Ô∏è VEREDICTO: {machine_check}")
            elif "CUMPLE" in machine_check: st.success(f"‚úÖ VEREDICTO: {machine_check}")
            else: st.info(f"‚ùì VEREDICTO: {machine_check}")

            st.write(f"**Justificaci√≥n:** {machine_result.get('narrative', 'N/A')}")
            st.code(json.dumps(machine_result, indent=2), language="json")

        # Columna del Humano
        with col_human_output:
            st.markdown("#### Veredicto Humano Declarado")
            human_check = human_verdict.upper().replace("RIESGO ALTO", "RIESGO").replace("RIESGO MEDIO", "RIESGO")
            if "RIESGO" in human_check: st.warning(f"‚ö†Ô∏è VEREDICTO: {human_verdict}")
            elif "CUMPLE" in human_check: st.success(f"‚úÖ VEREDICTO: {human_verdict}")
            else: st.info(f"‚ùì VEREDICTO: {human_verdict}")
            st.write(f"**Brecha:** {human_gap}")
            st.markdown("---")
            
        st.subheader("3. Conclusi√≥n: An√°lisis de Coincidencia")
        
        # Comparaci√≥n
        if machine_check == human_check.strip():
            st.balloons()
            st.success(f"üéØ COINCIDENCIA PERFECTA (Kappa Score: 1.0) | Ambos veredictos coinciden en: **{machine_check}**.")
            st.markdown("**VALIDACI√ìN TOTAL:** El motor de IA replica la l√≥gica de auditor√≠a experta. **M√°xima Integridad y Trazabilidad.**")
        else:
            st.error(f"‚ùå NO COINCIDENCIA | M√°quina: **{machine_check}** vs. Humano: **{human_verdict}**.")
            st.warning("‚ö†Ô∏è **ALERTA:** Esto activa un protocolo de Calibraci√≥n Humano-en-el-Bucle (HITL) para investigar la divergencia.")

if __name__ == "__main__":
    main()
